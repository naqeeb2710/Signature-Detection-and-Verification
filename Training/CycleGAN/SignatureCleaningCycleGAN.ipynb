{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wNjDKdQy35h"
   },
   "source": [
    "# Clone CycleGAN official Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TRm-USlsHgEV"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z1EySlOXwwoa"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ryyp9cwxfsyT"
   },
   "outputs": [],
   "source": [
    "!pip install visdom\n",
    "!pip install dominate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8daqlgVhw29P"
   },
   "source": [
    "# Using Custom dataset\n",
    "Custom datasets need to be organized in a particular format\n",
    "-   Create a dataset folder under `/dataset` for custom dataset.\n",
    "-   Create subfolders `testA`, `testB`, `trainA`, and `trainB` under thr dataset's folder. \n",
    "In trainA/testA, place the clean images (domainA) and in trainB/testB, place the noisy images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFw1kDQBx3LN"
   },
   "source": [
    "# Training\n",
    "\n",
    "-   `python train.py --dataroot ./datasets/dataset_name --name model_name --model cycle_gan`\n",
    "\n",
    "Change the `--dataroot` and `--name` to the custom dataset's path and model's name.  \n",
    "Use `--gpu_ids 0,1,..` to train on multiple GPUs.  \n",
    "\n",
    "The model can translate the image in both directions (noisy to clean and clean to noisy). For our use case, we have to translate from noisy to clean. So after training, copy the latest Generator(B) `/checkpoints/model_name/latest_net_G_B.pth`  as `latest_net_G.pth` under `/checkpoints/model_name/latest_net_G.pth`.  \n",
    "Use `cp ./checkpoints/horse2zebra/latest_net_G_B.pth ./checkpoints/horse2zebra/latest_net_G.pth` (see under testing section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQ0LYly5tt8I"
   },
   "source": [
    "**I recommend you to refer [here](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/tips.md) and [here](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/qa.md). These will helps to clear a good amount of doubts and errors. Also I recommend you to go through the issues section of the repo if you faces any errors or doubts. Legand has it that you will find the solution for your miseries there.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0sp7TCT2x9dB"
   },
   "outputs": [],
   "source": [
    "!python train.py --dataroot ./datasets/gan_signdata_kaggle --name gan_signdata_kaggle --model cycle_gan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9S7OOwt4nKQF"
   },
   "source": [
    "**Training arguments**  \n",
    "By default, the model trains for 100 epochs, to train for more epochs, use --n_epochs #epoch_count. The model will be trained for (100 + epoch_count) epochs.  \n",
    "To continue training after you stop the training, use --continue_train and set --epoch_count epoch_number. This will resume the training from epoch_number epoch.  \n",
    "eg: --continue_train --epoch_count 110 will resume the training from epoch 110."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UkcaFZiyASl"
   },
   "source": [
    "# Testing\n",
    "\n",
    "-   `python test.py --dataroot datasets/dataset_name/testA --name model_name --model test --no_dropout`\n",
    "\n",
    "Change the `--dataroot` and `--name` to be consistent with your trained model's configuration.\n",
    "\n",
    "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
    "> The option --model test is used for generating results of CycleGAN only for one side. This option will automatically set --dataset_mode single, which only loads the images from one set. On the contrary, using --model cycle_gan requires loading and generating results in both directions, which is sometimes unnecessary. The results will be saved at ./results/. Use --results_dir {directory_path_to_save_result} to specify the results directory.\n",
    "\n",
    "> For your own experiments, you might want to specify --netG, --norm, --no_dropout to match the generator architecture of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bMlH2i5LPKFI"
   },
   "outputs": [],
   "source": [
    "cp ./checkpoints/gan_signdata_kaggle/latest_net_G_B.pth ./checkpoints/gan_signdata_kaggle/latest_net_G.pth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCsKkEq0yGh0"
   },
   "outputs": [],
   "source": [
    "!python test.py --dataroot datasets/gan_signdata_kaggle/testB --name gan_signdata_kaggle --model test --no_dropout"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SignatureCleaningCycleGAN",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
